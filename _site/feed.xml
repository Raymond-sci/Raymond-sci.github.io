<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-06-15T01:06:12+08:00</updated><id>http://localhost:4000/feed.xml</id><author><name>{&quot;firstname&quot;=&gt;&quot;Jiabo&quot;, &quot;lastname&quot;=&gt;&quot;Huang&quot;, &quot;nickname&quot;=&gt;&quot;Raymond&quot;, &quot;email&quot;=&gt;&quot;jiabo.huang@qmul.ac.uk&quot;, &quot;phone&quot;=&gt;&quot;+0044 07561775861&quot;, &quot;affliations&quot;=&gt;[{&quot;name&quot;=&gt;&quot;Computer Vision Group&quot;, &quot;link&quot;=&gt;&quot;http://www.dcs.qmul.ac.uk/research/vision/&quot;}, {&quot;name&quot;=&gt;&quot;School of Electronic Engineering and Computer Science&quot;, &quot;link&quot;=&gt;&quot;http://www.eecs.qmul.ac.uk/&quot;}, {&quot;name&quot;=&gt;&quot;Queen Mary Univserity of London&quot;, &quot;link&quot;=&gt;&quot;http://www.qmul.ac.uk/&quot;, &quot;address&quot;=&gt;[{&quot;line&quot;=&gt;&quot;Mile End Road&quot;}, {&quot;line&quot;=&gt;&quot;London, E1 4NS, UK&quot;}, {&quot;line&quot;=&gt;&quot;CS Room 329, Peter Landin Building&quot;}]}], &quot;thumb&quot;=&gt;&quot;asserts/home/thumb.jpg&quot;, &quot;github&quot;=&gt;&quot;https://github.com/Raymond-sci&quot;}</name><email>jiabo.huang@qmul.ac.uk</email></author><entry><title type="html">huang2020pica</title><link href="http://localhost:4000/projects/huang2020pica" rel="alternate" type="text/html" title="huang2020pica" /><published>2020-03-05T00:00:00+08:00</published><updated>2020-03-05T00:00:00+08:00</updated><id>http://localhost:4000/projects/huang2020pica</id><content type="html" xml:base="http://localhost:4000/projects/huang2020pica">&lt;p&gt;&lt;img src=&quot;/assets/project/huang2020pica/pipeline.jpg&quot; alt=&quot;cover&quot; width=&quot;90%&quot; class=&quot;center&quot; /&gt;
&lt;!--*Figure 1. Overview of the proposed Anchor Neighbourhood Discovery (AND) method for unsupervised deep learning.*{:.center}--&gt;&lt;/p&gt;

&lt;h2 id=&quot;description&quot;&gt;Description&lt;/h2&gt;

&lt;p&gt;Deep Clustering, which jointly optimises the objectives of representation learning and clustering with the help of deep learning techniques, is proposed to address the limitation of traditional cluster analysis algorithms when dealing with high-dimensional imagery data with indiscriminative visual representations. Although conducting cluster analysis with learnable representations holds the potential to benefit clustering on unlabelled data, how to improve the semantic plausibility of these clusters remains an open problem.&lt;/p&gt;

&lt;p&gt;Recent deep clustering models either iteratively estimate cluster assignment and/or inter-sample relations which are then used as hypotheses in supervising the learning of deep neural networks, or used in conjunction with cluster constraints. The alternate training strategy is susceptible to error-propagation due to inaccurate membership estimation. The simultaneous one, which usually supervised by pretext tasks that require good cluster structure, suffers from the vague connection between training supervision and cluster objectives. Without global solution-level guidance to select from all the possible separations, the resulted clusters tend to be semantically less plausible.&lt;/p&gt;

&lt;p&gt;In this work, we propose a deep clustering method called &lt;em&gt;PartItion Confidence mAximisation&lt;/em&gt; (PICA). Due to the high visual similarity shared by samples from the same semantic classes, assigning them into different clusters will reduce the resulted intra-cluster compactness and inter-cluster diversity, &lt;em&gt;i.e.&lt;/em&gt; lower partition confidence. Based on this insight, PICA is designed to encourage the model to learn the most &lt;em&gt;confident&lt;/em&gt; clusters from all the possible solutions in order to find the most semantically plausible inter-class separation. This is in spirit of traditional maximal margin clustering which also seeks for most separable clustering solutions with shallow models (&lt;em&gt;e.g.&lt;/em&gt; SVM), but differs notably in that both the feature representations and decision boundaries are end-to-end learned in our deep learning model. Specifically, a partition uncertainty index (PUI) is proposed to quantifies how confidently a deep model can make sense and separate a set of target images. A stochastic approximation of PUI is introduced to enable standard mini-batch based learning and a novel objective loss function is formulated for training with any off-the-shelf networks.&lt;/p&gt;

&lt;p&gt;Our &lt;em&gt;contributions&lt;/em&gt; are threefold:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;We propose the idea of learning the most semantically plausible clustering solution by maximising partition confidence, which extends the classical maximal margin clustering idea to the deep learning paradigm. 
&lt;!-- The proposed method makes no strong hypothesis on local inter-sample relations and/or cluster assignment which usually leads to error-propagation and inferior clustering solutions.  --&gt;&lt;/li&gt;
  &lt;li&gt;We introduce a novel deep clustering method, called &lt;em&gt;PartItion Confidence mAximisation&lt;/em&gt; (PICA) which is built upon a newly introduced partition uncertainty index that is designed elegantly to quantify the global confidence of the clustering solution. 
&lt;!-- To enable formulating a deep learning objective loss function, a novel transformation of the partition uncertainty index is further proposed. PICA can be trained end-to-end using a single objective loss function without whistles and bells (*e.g.* complex multi-stage alternation and multiple loss functions) to simultaneously learn a deep neural network and cluster assignment that can be mapped to the semantic category one-to-one. --&gt;&lt;/li&gt;
  &lt;li&gt;A stochastic approximation of the partition uncertainty index is formulated to decouple it from the whole set of target images, therefore, enabling a ready adoption of the standard mini-batch model training.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;benchmarks&quot;&gt;Benchmarks&lt;/h2&gt;
&lt;p&gt;Extensive experiments are conducted on six challenging objects recognition benchmarks which demonstrates the advantages of PICA over a wide range of the state-of-the-art approaches.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;CIFAR10(/100)&lt;/strong&gt;: A natural image dataset with 50,000/10,000 samples from 10(/100) classes for training and testing respectively.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;STL10&lt;/strong&gt;: An ImageNet sourced dataset containing 500/800 training/test images from each of 10 classes and additional 100,000 samples from several unknown categories.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;ImageNet-10 and ImageNet-Dogs&lt;/strong&gt;:
Two subsets of ImageNet: the former with 10 random selected subjects and the latter with 15 dog breeds.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tiny-ImageNet&lt;/strong&gt;: A subset of ImageNet with 200 classes. There are 100,000/10,000 training/test images evenly distributed in each category.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Please kindly refer to the &lt;a href=&quot;/assets/project/huang2020pica/paper.pdf&quot;&gt;paper&lt;/a&gt; for more details and feel free to reach &lt;a href=&quot;http://localhost:4000&quot;&gt;me&lt;/a&gt; for any question.&lt;/p&gt;</content><author><name>{&quot;firstname&quot;=&gt;&quot;Jiabo&quot;, &quot;lastname&quot;=&gt;&quot;Huang&quot;, &quot;nickname&quot;=&gt;&quot;Raymond&quot;, &quot;email&quot;=&gt;&quot;jiabo.huang@qmul.ac.uk&quot;, &quot;phone&quot;=&gt;&quot;+0044 07561775861&quot;, &quot;affliations&quot;=&gt;[{&quot;name&quot;=&gt;&quot;Computer Vision Group&quot;, &quot;link&quot;=&gt;&quot;http://www.dcs.qmul.ac.uk/research/vision/&quot;}, {&quot;name&quot;=&gt;&quot;School of Electronic Engineering and Computer Science&quot;, &quot;link&quot;=&gt;&quot;http://www.eecs.qmul.ac.uk/&quot;}, {&quot;name&quot;=&gt;&quot;Queen Mary Univserity of London&quot;, &quot;link&quot;=&gt;&quot;http://www.qmul.ac.uk/&quot;, &quot;address&quot;=&gt;[{&quot;line&quot;=&gt;&quot;Mile End Road&quot;}, {&quot;line&quot;=&gt;&quot;London, E1 4NS, UK&quot;}, {&quot;line&quot;=&gt;&quot;CS Room 329, Peter Landin Building&quot;}]}], &quot;thumb&quot;=&gt;&quot;asserts/home/thumb.jpg&quot;, &quot;github&quot;=&gt;&quot;https://github.com/Raymond-sci&quot;}</name><email>jiabo.huang@qmul.ac.uk</email></author><category term="accepted" /><category term="public" /><category term="uploaded" /><category term="project-page" /><category term="open-sourced" /><summary type="html"></summary></entry><entry><title type="html">huang2020pad</title><link href="http://localhost:4000/projects/huang2020pad" rel="alternate" type="text/html" title="huang2020pad" /><published>2019-12-11T00:00:00+08:00</published><updated>2019-12-11T00:00:00+08:00</updated><id>http://localhost:4000/projects/huang2020pad</id><content type="html" xml:base="http://localhost:4000/projects/huang2020pad">&lt;p&gt;&lt;img src=&quot;/assets/project/huang2020pad/pipeline.jpg&quot; alt=&quot;cover&quot; width=&quot;90%&quot; class=&quot;center&quot; /&gt;
&lt;!--*Figure 1. Overview of the proposed Anchor Neighbourhood Discovery (AND) method for unsupervised deep learning.*{:.center}--&gt;&lt;/p&gt;

&lt;h2 id=&quot;description&quot;&gt;Description&lt;/h2&gt;
&lt;p&gt;Convolutional neural networks (CNNs) trained in a supervised fashion have significantly boosted the state-of-the-art performance in computer vision. Moreover, the feature representations of a supervised CNN (e.g. trained for classification on ImageNet) generalise to new tasks. Despite such remarkable success, this approach is limited due to a number of stringent assumptions that do not always hold valid. Due to the only need for access of unlabelled data typically available at scale, unsupervised deep learning provides a conceptually generic and scalable solution to these limitations.&lt;/p&gt;

&lt;p&gt;One intuitive strategy for unsupervised deep learning is joint learning of feature representations and data clustering. This objective is extremely hard due to the numerous combinatorial configurations of unlabelled data alongside highly complex inter-class decision boundaries. To avoid clustering errors as well as the following propagation, instance learning is proposed whereby every single sample is treated as an independent class. However, this simplified supervision is often rather ambiguous particularly around class centres, therefore, leading to weak class discrimination. As an intermediate representation, tiny neighbourhoods are leveraged for preserving the advantages of both data
clustering and instance learning. But this method is restricted by the small size of local neighbourhoods.&lt;/p&gt;

&lt;p&gt;In this work, we aim to solve the algorithmic limitations of existing unsupervised deep learning methods. To that end, we propose a general-purpose &lt;em&gt;Progressive Affinity Diffusion&lt;/em&gt; (PAD) method for training unsupervised models. Requiring no prior knowledge of class number, PAD performs
model-matureness-adaptive data group inference in training for more reliably revealing the underlying sample-to-class memberships.&lt;/p&gt;

&lt;p&gt;We make three contributions:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;We propose a novel idea of leveraging strongly connected subgraphs as a self-supervision structure for more reliable unsupervised deep learning.&lt;/li&gt;
  &lt;li&gt;We formulate a &lt;em&gt;Progressive Affinity Diffusion&lt;/em&gt; (PAD) method for modelmatureness-adaptive discovery of strongly connected subgraphs during training through affinity diffusion across adjacent neighbourhoods.&lt;/li&gt;
  &lt;li&gt;We design a group structure aware objective loss formulation for more discriminative capitalising of strongly connected subgraphs in model representation learning.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;benchmarks&quot;&gt;Benchmarks&lt;/h2&gt;
&lt;p&gt;Extensive experiments are conducted on both image classification and cluster analysis using the following six datasets and the results show the advantages of our PAD method over a wide variety of existing state-of-the-art approaches.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;CIFAR10(/100)&lt;/strong&gt;: An image dataset with 50,000/10,000 train/test images from 10 (/100) object classes.Each class has 6,000 (/600) images with size &lt;script type=&quot;math/tex&quot;&gt;32\!\times\!32&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;SVHN&lt;/strong&gt;: A Street View House Numbers dataset including 10 classes of digit images.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;ImageNet&lt;/strong&gt;: A large 1,000 classes object dataset with 1.2 million images for training and 50,000 for test.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;MNIST&lt;/strong&gt;: A hand-written digits dataset with 60,000/10,000 train/test images from 10 digit classes.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;STL10&lt;/strong&gt;: An ImageNet adapted dataset containing 500/800 train/test samples from 10 classes as well as 100,000 unlabelled images from auxiliary unknown classes.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Please kindly refer to the &lt;a href=&quot;/assets/project/huang2020pad/paper.pdf&quot;&gt;paper&lt;/a&gt; for more details and feel free to reach &lt;a href=&quot;http://localhost:4000&quot;&gt;me&lt;/a&gt; for any question.&lt;/p&gt;</content><author><name>{&quot;firstname&quot;=&gt;&quot;Jiabo&quot;, &quot;lastname&quot;=&gt;&quot;Huang&quot;, &quot;nickname&quot;=&gt;&quot;Raymond&quot;, &quot;email&quot;=&gt;&quot;jiabo.huang@qmul.ac.uk&quot;, &quot;phone&quot;=&gt;&quot;+0044 07561775861&quot;, &quot;affliations&quot;=&gt;[{&quot;name&quot;=&gt;&quot;Computer Vision Group&quot;, &quot;link&quot;=&gt;&quot;http://www.dcs.qmul.ac.uk/research/vision/&quot;}, {&quot;name&quot;=&gt;&quot;School of Electronic Engineering and Computer Science&quot;, &quot;link&quot;=&gt;&quot;http://www.eecs.qmul.ac.uk/&quot;}, {&quot;name&quot;=&gt;&quot;Queen Mary Univserity of London&quot;, &quot;link&quot;=&gt;&quot;http://www.qmul.ac.uk/&quot;, &quot;address&quot;=&gt;[{&quot;line&quot;=&gt;&quot;Mile End Road&quot;}, {&quot;line&quot;=&gt;&quot;London, E1 4NS, UK&quot;}, {&quot;line&quot;=&gt;&quot;CS Room 329, Peter Landin Building&quot;}]}], &quot;thumb&quot;=&gt;&quot;asserts/home/thumb.jpg&quot;, &quot;github&quot;=&gt;&quot;https://github.com/Raymond-sci&quot;}</name><email>jiabo.huang@qmul.ac.uk</email></author><category term="accepted" /><category term="public" /><category term="uploaded" /><category term="project-page" /><summary type="html"></summary></entry><entry><title type="html">huang2019and</title><link href="http://localhost:4000/projects/huang2019and" rel="alternate" type="text/html" title="huang2019and" /><published>2019-04-25T00:00:00+08:00</published><updated>2019-04-25T00:00:00+08:00</updated><id>http://localhost:4000/projects/huang2019and</id><content type="html" xml:base="http://localhost:4000/projects/huang2019and">&lt;p&gt;&lt;img src=&quot;/assets/project/huang2019and/training-pipeline.jpg&quot; alt=&quot;cover&quot; width=&quot;90%&quot; class=&quot;center&quot; /&gt;
&lt;!--*Figure 1. Overview of the proposed Anchor Neighbourhood Discovery (AND) method for unsupervised deep learning.*{:.center}--&gt;&lt;/p&gt;

&lt;h2 id=&quot;description&quot;&gt;Description&lt;/h2&gt;
&lt;p&gt;Deep neural networks have significantly advanced the progress of computer vision problems, nevertheless, most of them are heavily relying on massive collection of exhaustively labelled training data. As such, unsupervised learning of deep features has recently drawn increasing attention.&lt;/p&gt;

&lt;p&gt;In the literature, representative unsupervised deep learning methods include clustering and sample specificity analysis. Methods fall in the former category has great potential with the best case reaching the performance of supervised learning but is error-prone. In contrast, sample specificity learning treats every single sample as an independent class and hypothesis that the model can reveal the underlying class-to-class semantic similarity structure. However, the ambiguous supervision leads to its weak discriminative ability. Other contemporary methods like self-supervised learning and data synthesis share a similar limitation due to the insufficient correlation between the auxiliary supervision and the underlying class target.&lt;/p&gt;

&lt;p&gt;We present a generic unsupervised deep learning method called &lt;em&gt;Anchor Neighbourhood Discovery&lt;/em&gt; (AND). With a &lt;em&gt;divide-and-conquer&lt;/em&gt; principle, the AND discovers class consistent neighbourhoods anchored to individual training samples (&lt;em&gt;divide&lt;/em&gt;) and propagates the local inter-sample class relationships within such neighbourhoods (&lt;em&gt;conquer&lt;/em&gt;) for more reliably extracting the latent discrimination information during model training.&lt;/p&gt;

&lt;p&gt;We make three contributions:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;We propose the idea of exploiting local neighbourhoods for unsupervised deep learning. To our best knowledge, it is the first attempt at exploring the concept of neighbourhood for end-to-end unsupervised deep learning of visual features.&lt;/li&gt;
  &lt;li&gt;We formulate an &lt;em&gt;Anchor Neighbourhood Discovery&lt;/em&gt; (AND) approach to progressive unsupervised deep learning.&lt;/li&gt;
  &lt;li&gt;We further introduce a curriculum learning algorithm to gradually perform neighbourhood discovery for maximising the class consistency of neighbourhoods therefore enhancing the unsupervised learning capability.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;benchmarks&quot;&gt;Benchmarks&lt;/h2&gt;
&lt;p&gt;Extensive experiments are conducted on the following six datasets and the results show the advantages of our AND method over a wide variety of existing state-of-the-art unsupervised deep learning models.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;CIFAR10(/100)&lt;/strong&gt;: An image dataset with 50,000/10,000 train/test images from 10 (/100) object classes.Each class has 6,000 (/600) images with size &lt;script type=&quot;math/tex&quot;&gt;32\!\times\!32&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;SVHN&lt;/strong&gt;: A Street View House Numbers dataset including 10 classes of digit images.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;ImageNet&lt;/strong&gt;: A large 1,000 classes object dataset with 1.2 million images for training and 50,000 for test.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;CUB200-2011&lt;/strong&gt;: A fine-grained dataset containing 5,994/5,794 train/test images of 200 bird species.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Stanford Dogs&lt;/strong&gt;: A fine-grained dataset with 12,000/8,580 train/test images of 120 dog breeds.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Please kindly refer to the &lt;a href=&quot;https://arxiv.org/abs/1904.11567&quot;&gt;paper&lt;/a&gt; for more details and feel free to reach &lt;a href=&quot;http://localhost:4000&quot;&gt;me&lt;/a&gt; for any question.&lt;/p&gt;</content><author><name>{&quot;firstname&quot;=&gt;&quot;Jiabo&quot;, &quot;lastname&quot;=&gt;&quot;Huang&quot;, &quot;nickname&quot;=&gt;&quot;Raymond&quot;, &quot;email&quot;=&gt;&quot;jiabo.huang@qmul.ac.uk&quot;, &quot;phone&quot;=&gt;&quot;+0044 07561775861&quot;, &quot;affliations&quot;=&gt;[{&quot;name&quot;=&gt;&quot;Computer Vision Group&quot;, &quot;link&quot;=&gt;&quot;http://www.dcs.qmul.ac.uk/research/vision/&quot;}, {&quot;name&quot;=&gt;&quot;School of Electronic Engineering and Computer Science&quot;, &quot;link&quot;=&gt;&quot;http://www.eecs.qmul.ac.uk/&quot;}, {&quot;name&quot;=&gt;&quot;Queen Mary Univserity of London&quot;, &quot;link&quot;=&gt;&quot;http://www.qmul.ac.uk/&quot;, &quot;address&quot;=&gt;[{&quot;line&quot;=&gt;&quot;Mile End Road&quot;}, {&quot;line&quot;=&gt;&quot;London, E1 4NS, UK&quot;}, {&quot;line&quot;=&gt;&quot;CS Room 329, Peter Landin Building&quot;}]}], &quot;thumb&quot;=&gt;&quot;asserts/home/thumb.jpg&quot;, &quot;github&quot;=&gt;&quot;https://github.com/Raymond-sci&quot;}</name><email>jiabo.huang@qmul.ac.uk</email></author><category term="accepted" /><category term="public" /><category term="open-sourced" /><category term="project-page" /><category term="uploaded" /><summary type="html"></summary></entry></feed>