<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-05-03T23:32:32+01:00</updated><id>http://localhost:4000/feed.xml</id><author><name>{&quot;firstname&quot;=&gt;&quot;Jiabo&quot;, &quot;lastname&quot;=&gt;&quot;Huang&quot;, &quot;nickname&quot;=&gt;&quot;Raymond&quot;, &quot;email&quot;=&gt;&quot;jiabo.huang@qmul.ac.uk&quot;, &quot;phone&quot;=&gt;&quot;+0044 07561775861&quot;, &quot;affliations&quot;=&gt;[{&quot;name&quot;=&gt;&quot;Computer Vision Group&quot;, &quot;link&quot;=&gt;&quot;http://www.dcs.qmul.ac.uk/research/vision/&quot;}, {&quot;name&quot;=&gt;&quot;School of Electronic Engineering and Computer Science&quot;, &quot;link&quot;=&gt;&quot;http://www.eecs.qmul.ac.uk/&quot;}, {&quot;name&quot;=&gt;&quot;Queen Mary Univserity of London&quot;, &quot;link&quot;=&gt;&quot;http://www.qmul.ac.uk/&quot;, &quot;address&quot;=&gt;[{&quot;line&quot;=&gt;&quot;Mile End Road&quot;}, {&quot;line&quot;=&gt;&quot;London E1 4NS, UK&quot;}, {&quot;line&quot;=&gt;&quot;CS Room 329&quot;}]}], &quot;thumb&quot;=&gt;&quot;asserts/home/thumb.jpg&quot;, &quot;github&quot;=&gt;&quot;https://github.com/Raymond-sci&quot;}</name><email>jiabo.huang@qmul.ac.uk</email></author><entry><title type="html">huang2019and</title><link href="http://localhost:4000/projects/huang2019and" rel="alternate" type="text/html" title="huang2019and" /><published>2019-04-25T00:00:00+01:00</published><updated>2019-04-25T00:00:00+01:00</updated><id>http://localhost:4000/projects/huang2019and</id><content type="html" xml:base="http://localhost:4000/projects/huang2019and">&lt;p&gt;&lt;img src=&quot;/assets/project/huang2019and/training-pipeline.jpg&quot; alt=&quot;cover&quot; width=&quot;90%&quot; class=&quot;center&quot; /&gt;
&lt;!--*Figure 1. Overview of the proposed Anchor Neighbourhood Discovery (AND) method for unsupervised deep learning.*{:.center}--&gt;&lt;/p&gt;

&lt;h2 id=&quot;description&quot;&gt;Description&lt;/h2&gt;
&lt;p&gt;Deep neural networks have significantly advanced the progress of computer vision problems, nevertheless, most of them are heavily relying on massive collection of exhaustively labelled training data. As such, unsupervised learning of deep features has recently drawn increasing attention.&lt;/p&gt;

&lt;p&gt;In the literature, representative unsupervised deep learning methods include clustering and sample specificity analysis. Methods fall in the former category has great potential with the best case reaching the performance of supervised learning but is error-prone. In contrast, sample specificity learning treats every single sample as an independent class and hypothesis that the model can reveal the underlying class-to-class semantic similarity structure. However, the ambiguous supervision leads to its weak discriminative ability. Other contemporary methods like self-supervised learning and data synthesis share a similar limitation due to the insufficient correlation between the auxiliary supervision and the underlying class target.&lt;/p&gt;

&lt;p&gt;We present a generic unsupervised deep learning method called &lt;em&gt;Anchor Neighbourhood Discovery&lt;/em&gt; (AND). With a &lt;em&gt;divide-and-conquer&lt;/em&gt; principle, the AND discovers class consistent neighbourhoods anchored to individual training samples (&lt;em&gt;divide&lt;/em&gt;) and propagates the local inter-sample class relationships within such neighbourhoods (&lt;em&gt;conquer&lt;/em&gt;) for more reliably extracting the latent discrimination information during model training.&lt;/p&gt;

&lt;p&gt;We make three contributions:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;We propose the idea of exploiting local neighbourhoods for unsupervised deep learning. To our best knowledge, it is the first attempt at exploring the concept of neighbourhood for end-to-end unsupervised deep learning of visual features.&lt;/li&gt;
  &lt;li&gt;We formulate an &lt;em&gt;Anchor Neighbourhood Discovery&lt;/em&gt; (AND) approach to progressive unsupervised deep learning.&lt;/li&gt;
  &lt;li&gt;We further introduce a curriculum learning algorithm to gradually perform neighbourhood discovery for maximising the class consistency of neighbourhoods therefore enhancing the unsupervised learning capability.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;benchmarks&quot;&gt;Benchmarks&lt;/h2&gt;
&lt;p&gt;Extensive experiments are conducted on the following six datasets and the results show the advantages of our AND method over a wide variety of existing state-of-the-art unsupervised deep learning models.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;CIFAR10(/100)&lt;/strong&gt;: An image dataset with 50,000/10,000 train/test images from 10 (/100) object classes.Each class has 6,000 (/600) images with size &lt;script type=&quot;math/tex&quot;&gt;32\!\times\!32&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;SVHN&lt;/strong&gt;: A Street View House Numbers dataset including 10 classes of digit images.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;ImageNet&lt;/strong&gt;: A large 1,000 classes object dataset with 1.2 million images for training and 50,000 for test.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;CUB200-2011&lt;/strong&gt;: A fine-grained dataset containing 5,994/5,794 train/test images of 200 bird species.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Stanford Dogs&lt;/strong&gt;: A fine-grained dataset with 12,000/8,580 train/test images of 120 dog breeds.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Please kindly refer to the &lt;a href=&quot;https://arxiv.org/abs/1904.11567&quot;&gt;paper&lt;/a&gt; for more details and feel free to reach &lt;a href=&quot;http://localhost:4000&quot;&gt;me&lt;/a&gt; for any question.&lt;/p&gt;</content><author><name>{&quot;firstname&quot;=&gt;&quot;Jiabo&quot;, &quot;lastname&quot;=&gt;&quot;Huang&quot;, &quot;nickname&quot;=&gt;&quot;Raymond&quot;, &quot;email&quot;=&gt;&quot;jiabo.huang@qmul.ac.uk&quot;, &quot;phone&quot;=&gt;&quot;+0044 07561775861&quot;, &quot;affliations&quot;=&gt;[{&quot;name&quot;=&gt;&quot;Computer Vision Group&quot;, &quot;link&quot;=&gt;&quot;http://www.dcs.qmul.ac.uk/research/vision/&quot;}, {&quot;name&quot;=&gt;&quot;School of Electronic Engineering and Computer Science&quot;, &quot;link&quot;=&gt;&quot;http://www.eecs.qmul.ac.uk/&quot;}, {&quot;name&quot;=&gt;&quot;Queen Mary Univserity of London&quot;, &quot;link&quot;=&gt;&quot;http://www.qmul.ac.uk/&quot;, &quot;address&quot;=&gt;[{&quot;line&quot;=&gt;&quot;Mile End Road&quot;}, {&quot;line&quot;=&gt;&quot;London E1 4NS, UK&quot;}, {&quot;line&quot;=&gt;&quot;CS Room 329&quot;}]}], &quot;thumb&quot;=&gt;&quot;asserts/home/thumb.jpg&quot;, &quot;github&quot;=&gt;&quot;https://github.com/Raymond-sci&quot;}</name><email>jiabo.huang@qmul.ac.uk</email></author><category term="accepted" /><category term="public" /><category term="open-sourced" /><category term="project-page" /><category term="uploaded" /><summary type="html"></summary></entry></feed>